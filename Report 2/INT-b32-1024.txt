[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "Turing" with compute capability 7.5

MatrixA(320,320), MatrixB(640,320)
Computing result using CUDA Kernel...
done
Performance= 583.99 GFlop/s, Time= 0.224 msec, Size= 131072000 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Operating System Runtime API Statistics:

 Time (%)  Total Time (ns)  Num Calls    Avg (ns)     Med (ns)    Min (ns)   Max (ns)     StdDev (ns)        Name
 --------  ---------------  ---------  ------------  -----------  --------  -----------  -------------  --------------
     71,0      380 274 036          5  76 054 807,0    333 081,0    63 679  379 022 244  169 364 166,0  sem_wait
     18,0      100 295 750         13   7 715 057,0  1 116 592,0     1 720   63 104 627   17 440 660,0  poll
      5,0       29 312 675        504      58 160,0      9 531,0     1 003    9 506 698      460 337,0  ioctl
      3,0       17 137 236         41     417 981,0      3 622,0     1 018   16 852 915    2 630 882,0  fopen
      0,0          916 541         31      29 565,0      2 621,0     2 100      653 117      116 149,0  mmap64
      0,0          527 404         10      52 740,0     37 737,0     4 491      214 501       57 907,0  sem_timedwait
      0,0          312 617         49       6 379,0      5 796,0     2 118       20 895        2 762,0  open64
      0,0          254 092         17      14 946,0      4 362,0     1 090      165 294       39 260,0  mmap
      0,0          236 811          5      47 362,0     34 192,0    18 339      107 326       36 221,0  pthread_create
      0,0          191 883          6      31 980,0     31 401,0    17 812       47 887       12 231,0  fgets
      0,0           79 530         18       4 418,0      4 611,0     1 002       11 486        2 721,0  fclose
      0,0           27 380          5       5 476,0      4 334,0     2 422       12 592        4 157,0  open
      0,0           19 290          4       4 822,0      5 339,0     1 695        6 917        2 330,0  fread
      0,0           18 667          5       3 733,0      2 019,0     1 034        7 840        3 274,0  read
      0,0           12 966          5       2 593,0      2 062,0     1 727        4 712        1 229,0  munmap
      0,0           12 145          1      12 145,0     12 145,0    12 145       12 145            0,0  fopen64
      0,0           10 527          2       5 263,0      5 263,0     4 811        5 716          639,0  socket
      0,0            9 683          7       1 383,0      1 151,0     1 071        2 201          415,0  write
      0,0            6 826          1       6 826,0      6 826,0     6 826        6 826            0,0  connect
      0,0            5 095          1       5 095,0      5 095,0     5 095        5 095            0,0  pipe2
      0,0            1 928          1       1 928,0      1 928,0     1 928        1 928            0,0  bind
      0,0            1 680          1       1 680,0      1 680,0     1 680        1 680            0,0  fcntl

[5/8] Executing 'cudaapisum' stats report

CUDA API Statistics:

 Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)     Min (ns)    Max (ns)   StdDev (ns)            Name
 --------  ---------------  ---------  ------------  ------------  ----------  ----------  -----------  -------------------------
     97,0       66 771 251          1  66 771 251,0  66 771 251,0  66 771 251  66 771 251          0,0  cudaEventSynchronize
      0,0          533 069        301       1 771,0       1 671,0       1 606      17 473        920,0  cudaLaunchKernel
      0,0          489 980          3     163 326,0       3 030,0       2 789     484 161    277 850,0  cudaHostAlloc
      0,0          419 724          2     209 862,0     209 862,0      86 045     333 679    175 103,0  cudaStreamSynchronize
      0,0          335 158          3     111 719,0       5 488,0       2 288     327 382    186 776,0  cudaFreeHost
      0,0           81 856          3      27 285,0       2 027,0       1 290      78 539     44 388,0  cudaMalloc
      0,0           53 986          3      17 995,0       4 152,0       1 352      48 482     26 439,0  cudaFree
      0,0           19 248          3       6 416,0       4 396,0       2 318      12 534      5 399,0  cudaMemcpyAsync
      0,0            8 704          1       8 704,0       8 704,0       8 704       8 704          0,0  cudaStreamCreateWithFlags
      0,0            6 502          2       3 251,0       3 251,0         481       6 021      3 917,0  cudaEventCreate
      0,0            3 594          2       1 797,0       1 797,0       1 276       2 318        736,0  cudaEventRecord
      0,0            1 104          2         552,0         552,0         262         842        410,0  cudaEventDestroy
      0,0              612          1         612,0         612,0         612         612          0,0  cuModuleGetLoadingMode

[6/8] Executing 'gpukernsum' stats report

CUDA Kernel Statistics:

 Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                             Name
 --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ----------------------------------------------------------
    100,0       67 275 979        301  223 508,0  223 520,0   222 752   224 224        219,0  void MatrixMulCUDA<(int)32>(int *, int *, int *, int, int)

[7/8] Executing 'gpumemtimesum' stats report

CUDA Memory Operation Statistics (by time):

 Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation
 --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------
     60,0          120 160      2  60 080,0  60 080,0    33 312    86 848     37 855,0  [CUDA memcpy HtoD]
     39,0           79 552      1  79 552,0  79 552,0    79 552    79 552          0,0  [CUDA memcpy DtoH]

[8/8] Executing 'gpumemsizesum' stats report

CUDA Memory Operation Statistics (by size):

 Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation
 ----------  -----  --------  --------  --------  --------  -----------  ------------------
 1,229           2  0,614     0,614     0,410     0,819     0,290        [CUDA memcpy HtoD]
 0,819           1  0,819     0,819     0,819     0,819     0,000        [CUDA memcpy DtoH]
